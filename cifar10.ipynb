{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOf+2FdjYFg42WpAM4jcZaF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abinash2555/AI-Computer-Vision/blob/main/cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfeRZqOTv6V6"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.datasets.cifar10 import load_data\n",
        "from tensorflow.keras.applications.resnet import  ResNet50\n",
        "from tensorflow.keras.layers import Input , UpSampling2D , GlobalAveragePooling2D , Flatten , Dense , BatchNormalization\n",
        "from tensorflow.nn import relu , softmax\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCShRrjxv_ej",
        "outputId": "b129b8b4-5425-430d-c0ae-cdd1300314c3"
      },
      "source": [
        "(train_images , train_label) , (test_images , test_label) = load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "743LVPTDwThK",
        "outputId": "84152f9a-bb29-4405-eaae-508bacfae2d2"
      },
      "source": [
        "print(\"Shape of train_images is : \",train_images.shape)\n",
        "print(\"Shape of train_label is : \",train_label.shape)\n",
        "print(\"Shape of test_images is : \",test_images.shape)\n",
        "print(\"Shape of test_label is : \",test_label.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of train_images is :  (50000, 32, 32, 3)\n",
            "Shape of train_label is :  (50000, 1)\n",
            "Shape of test_images is :  (10000, 32, 32, 3)\n",
            "Shape of test_label is :  (10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqzBFr69wW6j",
        "outputId": "d5036a9b-74e6-4506-896a-3a8f009af707"
      },
      "source": [
        "\n",
        "train_label = tf.keras.utils.to_categorical(train_label)\n",
        "test_label  = tf.keras.utils.to_categorical(test_label)\n",
        "\n",
        "print(\"Shape of train_images is : \",train_images.shape)\n",
        "print(\"Shape of train_label is : \",train_label.shape)\n",
        "print(\"Shape of test_images is : \",test_images.shape)\n",
        "print(\"Shape of test_label is : \",test_label.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of train_images is :  (50000, 32, 32, 3)\n",
            "Shape of train_label is :  (50000, 10)\n",
            "Shape of test_images is :  (10000, 32, 32, 3)\n",
            "Shape of test_label is :  (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTC-eE_cwanP"
      },
      "source": [
        "train_images = train_images.astype('float64')\n",
        "train_data   = tf.keras.applications.resnet50.preprocess_input(train_images)\n",
        "test_images  = test_images.astype('float64')\n",
        "test_data    = tf.keras.applications.resnet50.preprocess_input(test_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "W1lvioL1wghy",
        "outputId": "341b7f0c-fd8a-474d-c243-3f46f3ebd04f"
      },
      "source": [
        "fig , ax = plt.subplots(1,5,figsize=(18,4))\n",
        "for i in range(5):\n",
        "    ax[i].imshow(train_data[random.randint(0,500)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1296x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6dQtcKqwkYh",
        "outputId": "7f5d4ad7-d023-467a-b961-9288cc0a4647"
      },
      "source": [
        "# Create or Initialize the resnet block\n",
        "pre_trained_model = ResNet50(\n",
        "    include_top=False ,\n",
        "    weights='imagenet',\n",
        "    input_shape=(224,224,3)\n",
        ")\n",
        "\n",
        "layer_name = \"conv5_block3_2_bn\"\n",
        "trainable  = False\n",
        "for layer in pre_trained_model.layers:\n",
        "    if layer.name == layer_name:\n",
        "        print(\"Layer name is : %s\"%(layer.name))\n",
        "        trainable = True\n",
        "    layer.trainable = trainable\n",
        "\n",
        "# Add Inputs , flatten and classsifier layer\n",
        "\n",
        "inputs = Input(shape = (32,32,3))\n",
        "x = UpSampling2D((7,7))(inputs)\n",
        "x = pre_trained_model(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(1024 , activation = relu)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(512 , activation = relu)(x)\n",
        "x = BatchNormalization()(x)\n",
        "output = Dense(10 , activation=softmax)(x)\n",
        "\n",
        "model = Model(inputs , output)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.RMSprop(lr=0.0001) ,\n",
        "    loss=tf.keras.losses.categorical_crossentropy ,\n",
        "    metrics=['acc']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "Layer name is : conv5_block3_2_bn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4_cdcQ_wqkE",
        "outputId": "e25ca234-1efc-42e0-9000-550f5e91bdd1"
      },
      "source": [
        "history = model.fit(\n",
        "    train_data,\n",
        "    train_label,\n",
        "    epochs=5,\n",
        "    validation_data = (test_data , test_label)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1183/1563 [=====================>........] - ETA: 33:04 - loss: 0.9262 - acc: 0.6905"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Z28_P8LwwEl"
      },
      "source": [
        "# Create or Initialize the resnet block\n",
        "pre_trained_model = ResNet50(\n",
        "    include_top=False ,\n",
        "    weights='imagenet',\n",
        "    input_shape=(224,224,3)\n",
        ")\n",
        "\n",
        "# Add Inputs , flatten and classsifier layer\n",
        "\n",
        "inputs = Input(shape = (32,32,3))\n",
        "x = UpSampling2D((7,7))(inputs)\n",
        "x = pre_trained_model(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(1024 , activation = relu)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(512 , activation = relu)(x)\n",
        "x = BatchNormalization()(x)\n",
        "output = Dense(10 , activation=softmax)(x)\n",
        "\n",
        "model = Model(inputs , output)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.RMSprop(lr=0.0001) ,\n",
        "    loss=tf.keras.losses.categorical_crossentropy ,\n",
        "    metrics=['acc']\n",
        ")\n",
        "\n",
        "history1 = model.fit(\n",
        "    train_data,\n",
        "    train_label,\n",
        "    epochs=5,\n",
        "    validation_data = (test_data , test_label)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2H72Z9Mw3HD"
      },
      "source": [
        "\n",
        "_ , ax = plt.subplots(1,2,figsize = (16,5))\n",
        "ax[0].plot(history.history['acc'])\n",
        "ax[0].plot(history.history['val_acc'])\n",
        "ax[0].set_title(\"Accurecy\")\n",
        "\n",
        "ax[1].plot(history.history['loss'])\n",
        "ax[1].plot(history.history['val_loss'])\n",
        "ax[1].set_title(\"Loss\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0QR-G5gxE4w"
      },
      "source": [
        "\n",
        "_ , ax = plt.subplots(1,2,figsize = (16,5))\n",
        "ax[0].plot(history1.history['acc'])\n",
        "ax[0].plot(history1.history['val_acc'])\n",
        "ax[0].set_title(\"Accurecy\")\n",
        "\n",
        "ax[1].plot(history1.history['loss'])\n",
        "ax[1].plot(history1.history['val_loss'])\n",
        "ax[1].set_title(\"Loss\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUqCo8FixINW"
      },
      "source": [
        "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "import urllib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mi7ugHEixLSe"
      },
      "source": [
        "frog_img_url = \"https://static.scientificamerican.com/sciam/cache/file/41DF7DA0-EE58-4259-AA815A390FB37C55_source.jpg\"\n",
        "frog_img_name = \"frog.jpg\"\n",
        "urllib.request.urlretrieve(frog_img_url , frog_img_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkLvzg6axO_b"
      },
      "source": [
        "frog_img = tf.keras.preprocessing.image.load_img(frog_img_name , target_size=(32,32,3))\n",
        "frog_img = tf.keras.preprocessing.image.img_to_array(frog_img)\n",
        "frog = tf.keras.applications.resnet50.preprocess_input(frog_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uafAq84axR04"
      },
      "source": [
        "plt.imshow(frog)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iktL32yGxUXF"
      },
      "source": [
        "pred = model.predict(frog[tf.newaxis,]).argmax()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeSJCgAsxWTq"
      },
      "source": [
        "\n",
        "classes[pred]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "231pvnNjxYV2"
      },
      "source": [
        "\n",
        "plt.imshow(frog_img.astype(\"float64\") / 255.0)\n",
        "plt.title(classes[pred])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kdrbfc80xbE6"
      },
      "source": [
        "plt.bar(list(range(0,10)) , model.predict(frog[tf.newaxis,])[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-_m_RLtxew6"
      },
      "source": [
        "def prediction(img_url):\n",
        "    img_name = \"img\"+str(random.randint(0,1000))+\".jpg\"\n",
        "    urllib.request.urlretrieve(img_url , img_name)\n",
        "    img_ = tf.keras.preprocessing.image.load_img(img_name , target_size=(32,32,3))\n",
        "    img_ = tf.keras.preprocessing.image.img_to_array(img_)\n",
        "    img = tf.keras.applications.resnet50.preprocess_input(img_)\n",
        "\n",
        "    p = model.predict(img[tf.newaxis,])\n",
        "    pred = p.argmax()\n",
        "\n",
        "    _ , ax = plt.subplots(1,2,figsize = (12,5))\n",
        "    ax[0].imshow(img_.astype(\"float64\") / 255.0)\n",
        "    ax[0].set_title(classes[pred])\n",
        "\n",
        "    ax[1].bar(list(range(0,10)) , p[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pmz5NKoJxhf5"
      },
      "source": [
        "prediction(\"https://static.scientificamerican.com/sciam/cache/file/41DF7DA0-EE58-4259-AA815A390FB37C55_source.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8JE7Zvixkk5"
      },
      "source": [
        "prediction(\"https://www.vet.upenn.edu/images/default-source/penn-vet-extra/2019/pve-2-19-nbc2.jpg?sfvrsn=8269eaba_0\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBOaABbRxo1L"
      },
      "source": [
        "\n",
        "prediction(\"https://etimg.etb2bimg.com/thumb/msid-76805464,imgsize-369078,width-800,height-434,overlay-etauto/etauto-originals-will-china-fade-away-on-the-indian-automobile-turf.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grCQ1pqnxsSA"
      },
      "source": [
        "prediction(\"https://live.staticflickr.com/65535/48764060802_f4d4f052a2_o.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}